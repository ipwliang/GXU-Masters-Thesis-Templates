%% 中文摘要
\section*{\ArticleTitle}
\begin{cnabstract}\addcontentsline{toc}{section}{摘\ 要}
\fontsize{14pt}{17.5pt}\selectfont %设置字体为四号，行间距1.25倍

% 本研究聚焦于雾天环境下交通小目标检测这一关键课题，旨在为智能交通系统和无人技术在复杂气象条件下的应用提供高效、鲁棒的解决方案。随着智能交通系统的快速发展，交通物体的检测与识别对于保障道路安全和优化交通管理具有不可替代的重要作用。然而，雾天等恶劣天气条件严重干扰了无人机拍摄图像的质量，导致基于良好天气图像训练的检测模型性能大幅下降，尤其对于小目标检测而言，挑战更为严峻。

% 雾天环境下交通小目标检测面临着多重问题与挑战。雾气的弥散作用导致图像能见度降低、对比度下降，目标轮廓模糊不清，边界难以辨认，这使得基于良好天气图像训练的检测模型难以适应，准确识别目标的能力受到极大限制。小目标在图像中所占像素比例极低，传统检测算法受限于分辨率和信息丢失问题，难以有效捕捉和识别这些小目标。在雾天条件下，小目标检测的难度被进一步放大，去雾过程可能导致目标细节的丢失，影响检测精度；不同去雾算法在不同雾天场景下的适用性和稳定性存在差异；去雾与检测算法的融合优化尚未达到理想状态，两者的协同作用未能充分发挥，导致整体检测系统的性能提升有限。

% 为应对上述挑战，本研究提出了一系列创新性的方法。在目标检测方面，以 YOLOv11 算法为基础，提出了改进的 EX-YOLO 算法。通过深入分析 YOLOv11 网络结构，发现其在交通小目标检测中存在浅层特征图分辨率不足、跨尺度特征融合效率低等问题。为此，引入了改进的特征融合模块 SPPC，融合 SPPF 模块的多尺度特征提取能力和 CAM 的特征增强能力，显著提升了对小目标的特征捕获能力。同时，采用轻量化的卷积模块 DBSS 替代原始模块，降低了计算复杂度，使其更适用于资源受限设备。此外，引入 NWD 损失函数与 DIoU 损失函数相结合，提高了对小目标定位的精准度。在图像去雾方面，基于 CycleGAN 网络提出了改进的 CGANFormer 算法。将 Transformer 模块与 CycleGAN 的生成器网络相结合，利用其自注意力机制捕捉图像全局依赖关系，突破了传统卷积局部感受野的限制，能够更精准地还原雾天图像中的细节信息，如物体边缘和纹理。同时，采用局部 - 全局结合的判别器架构，局部判别器关注图像细节特征，全局判别器把控图像宏观特征，提升了去雾图像的整体质量和视觉效果。

% 本研究方法在多个数据集上进行了全面验证，取得了显著的效果。EX-YOLO 算法在保持较高检测精度的同时大幅降低了计算量，与 YOLOv11s、YOLOv10s 和 YOLOv9s 等模型相比，在 mAP、P、R 等关键指标上均展现出优异的综合性能，尤其在小目标检测任务中具有很强的竞争力，有效平衡了精度与效率，满足了无人机等有限设备环境下的实际应用需求。CGANFormer算法与AOD-Net、FFA-Net、CGA-Net等网络模型对比，表现出更有效的去雾性能。CGANFormer 与 EX-YOLO 算法的结合在雾天图像去雾和目标检测联合实验中表现出色，在 FOG-TT100K 和 FOG-VisDrone 数据集上的精确度、召回率和 mAP 等指标上均取得显著提升，证明了该算法在无人机等资源受限设备上进行实时目标检测的可行性，有效解决了雾天环境下交通目标检测的难点问题。

% 本研究在雾天环境下交通小目标检测领域具有重要的意义。一方面，通过改进图像去雾和目标检测算法，为智能交通系统在恶劣天气条件下的稳定运行提供了技术保障，有助于提高道路安全和交通管理效率。另一方面，研究成果推动了计算机视觉技术在无人领域的应用，为无人机在复杂环境中的交通监测、目标识别等任务提供了更可靠的解决方案，促进了无人技术的进一步发展。此外，本研究提出的算法在保持高性能的同时降低了计算资源需求，有利于降低智能交通系统和无人设备的硬件成本，提高其实用性和可推广性。未来，随着相关技术的不断完善和优化，本研究成果有望在更广泛的交通场景和气象条件下发挥更大的作用，为构建更加智能、安全、高效的交通体系奠定坚实的基础。

本研究聚焦于雾天环境下交通小目标检测的前沿课题，致力于攻克低能见度条件下无人机拍摄图像中小目标识别的难题，为智能交通系统与无人技术的深度发展提供关键技术支持。雾天图像受大气散射模型影响，呈现出对比度降低、颜色失真及目标轮廓模糊等特征，致使传统检测算法性能显著退化，尤其对小目标的检测精度与召回率难以满足实际应用场景需求。在复杂交通场景中，小目标如行人、非机动车以及远处交通标志等，因所占像素比例极低且易受背景干扰，检测难度急剧攀升。

针对上述挑战，本文提出基于改进 YOLOv11 网络的交通小目标检测算法 EX-YOLO 与基于改进 CycleGAN 网络的去雾还原算法 CGANFormer，并将二者有机融合，构建出适配雾天场景的高效目标检测系统。在目标检测环节，EX-YOLO 算法引入多尺度特征融合模块 SPPC，融合 SPPF 模块的池化操作与 CAM 模块的多尺度卷积，有效增强小目标特征提取能力；搭载轻量化卷积模块 DBSS，以深度可分离卷积及 SimAM 注意力机制替代原始标准卷积，大幅削减计算量；采用 DIoU 损失与 NWD 损失函数相结合的优化策略，精准定位小目标。在图像去雾环节，CGANFormer 算法革新传统 CycleGAN 架构，将 Transformer 模块嵌入生成器网络，利用自注意力机制捕捉全局依赖关系，突破卷积局部感受野限制；判别器引入局部 - 全局结合架构，协同保障去雾图像细节与整体质量。

实验验证表明，EX-YOLO 算法相较于 YOLOv11s，在 TT100K 数据集上 mAP0.5 提升至 0.893，计算量降低至 17.0 GFLOPs；在 VisDrone 数据集上 mAP0.5 达 0.390，计算量仅 15.4 GFLOPs，较基准模型均有显著优化。CGANFormer 算法在 NYU2 数据集 PSNR 达 21.0121、SSIM 为 0.9426，在 Dense-Haze 数据集 PSNR 为 16.8625、SSIM 为 0.5879，去雾效果全面超越对比算法。二者融合后的系统在 FOG-TT100K 数据集上 mAP0.5 达 0.592，精确度与召回率分别提升至 0.699 和 0.449；在 FOG-VisDrone 数据集上 mAP0.5 为 0.397，精确度与召回率分别为 0.721 和 0.074，综合性能指标显著占优。

本研究的成果为雾天交通小目标检测开辟了新的路径，不仅有效提升了复杂气象条件下智能交通系统的感知能力，还为无人机在低能见度环境下的广泛应用奠定了坚实基础，推动了计算机视觉技术在实际交通管理与无人驾驶领域的深化落地，具有重大的现实意义与应用前景。
\\
\\
\heiti 关键词：
\songti 深度学习\ \ 雾天目标检测\ \ 改进YOLO算法\ \ 循环对抗生成网络\ \ Transformer模块

\end{cnabstract}
\pagebreak


%% 英文摘要
\section*{\ArticleTitleEn}
\begin{enabstract}\addcontentsline{toc}{section}{ABSTRACT}
\fontsize{14pt}{17.5pt}\selectfont %设置字体为四号，行间距1.25倍

% This research focuses on the key topic of detecting small traffic targets in foggy environments, aiming to provide efficient and robust solutions for the application of intelligent transportation systems and unmanned technologies under complex meteorological conditions. With the rapid development of intelligent transportation systems, the detection and identification of traffic objects plays an irreplaceable and important role in ensuring road safety and optimizing traffic management. However, bad weather conditions such as foggy days have seriously interfered with the quality of the images taken by drones, resulting in a significant decline in the performance of detection models based on good weather image training, especially for small target detection, which is more serious.

% Traffic small target detection faces multiple problems and challenges in a foggy environment. The diffusion effect of fog leads to reduced image visibility, reduced contrast, blurred target contours, and unrecognizable boundaries, which makes it difficult for detection models based on good weather image training to adapt, and the ability to accurately identify targets is greatly limited. The pixel ratio of small targets in the image is extremely low. Traditional detection algorithms are limited by resolution and information loss problems, and it is difficult to effectively capture and identify these small targets. Under the condition of foggy weather, the difficulty of small target detection is further amplified. The defogging process may lead to the loss of target details, affecting the detection accuracy. There are differences in the applicability and stability of different fogging algorithms in different foggy weather scenarios. The integration optimization of fogging and detection algorithms has not reached the ideal state, and the synergy of the two Failure to give full play has led to a limited improvement in the performance of the overall detection system.

% In order to meet the above challenges, this study puts forward a series of innovative methods. In terms of target detection, an improved EX-YOLO algorithm is proposed based on the YOLOv11 algorithm. Through in-depth analysis of the YOLOv11 network structure, it is found that it has problems such as insufficient resolution of shallow feature map and low cross-scale feature fusion efficiency in traffic small target detection. To this end, an improved feature fusion module SPPC has been introduced to integrate the multi-scale feature extraction ability of the SPPF module and the feature enhancement ability of CAM, which significantly improves the feature capture ability for small targets. At the same time, the use of lightweight convolutional module DBSS to replace the original module reduces the complexity of computing and makes it more suitable for resource-limited devices. In addition, the combination of the NWD loss function and the DIoU loss function has improved the accuracy of small target positioning. In terms of image defogging, an improved CGANFormer algorithm is proposed based on the CycleGAN network. Combining the Transformer module with CycleGAN's generator network, it uses its self-attention mechanism to capture the global dependency of images, breaks through the limitations of traditional convolutional local sensing fields, and can more accurately restore detailed information in the foggy images, such as object edges and textures. At the same time, the local-ground combined discister architecture is adopted. The local discisiser focuses on the detailed characteristics of the image, and the global discisifier controls the macro characteristics of the image, which improves the overall quality and visual effect of the defogging image.

% This research method has been comprehensively verified on multiple data sets and achieved remarkable results. The EX-YOLO algorithm greatly reduces the calculation amount while maintaining high detection accuracy. Compared with benchmark models such as YOLOv11s, YOLOv10s and YOLOv9s, it shows excellent comprehensive performance in key indicators such as mAP, P and R, especially in It has strong competitiveness in small target detection tasks, effectively balances accuracy and efficiency, and meets the actual application needs of limited equipment environments such as unmanned aerial vehicles. The combination of CGANFormer and EX-YOLO algorithm performed well in the joint experiments of foggy image defogging and target detection, and the accuracy, recall rate and mAP on the FOG-TT100K and FOG-VisDrone data sets are all taken. It has been significantly improved, and at the same time, the computing volume has been significantly reduced, showing a low computational complexity, which proves the feasibility of the algorithm for real-time target detection on resource-limited equipment such as drones, and effectively solves the difficult problem of traffic target detection in a foggy environment.

% This research is of great significance in the field of traffic small target detection in a foggy environment. On the one hand, by improving image defogging and target detection algorithms, it provides technical guarantee for the stable operation of intelligent traffic systems under bad weather conditions, which is conducive to improving road safety and traffic management efficiency. On the other hand, the research results have promoted the application of computer vision technology in the unmanned field, provided more reliable solutions for traffic monitoring, target identification and other tasks of drones in complex environments, and promoted the further development of unmanned technology. In addition, the algorithm proposed in this study reduces the demand for computing resources while maintaining high performance, which is conducive to reducing the hardware cost of intelligent transportation systems and unmanned equipment, and improving practicality and generalization. In the future, with the continuous improvement and optimization of relevant technologies, the results of this research are expected to play a greater role in a wider range of traffic scenarios and meteorological conditions, and lay a solid foundation for building a more intelligent, safe and efficient transportation system.

This research focuses on the cutting-edge topic of traffic small target detection in a foggy environment. It is committed to overcoming the problem of identifying small and small targets in drone images under low visibility conditions, and providing key technical support for the in-depth development of intelligent transportation systems and unmanned technology. Affected by the atmospheric scattering model, the foggy images show characteristics such as reduced contrast, color distortion and blurred target contours, resulting in a significant degradation of the performance of traditional detection algorithms. In particular, the detection accuracy and recall rate of small targets are difficult to meet the requirements of practical application scenarios. In complex traffic scenarios, small targets such as pedestrians, non-motorized vehicles and distant traffic signs, etc., are extremely low in pixel ratio and susceptible to background interference, and the difficulty of detection increases sharply.

In response to the above challenges, this paper proposes the traffic small target detection algorithm EX-YOLO based on the improvement of the YOLOv11 network and the defogging reduction algorithm CGANFormer based on the improvement of the CycleGAN network, and organically integrates the two to build an efficient target detection system adapted to the foggy scene. In the target detection link, the EX-YOLO algorithm introduces the multi-scale feature fusion module SPPC, integrates the pooled operation of the SPPF module and the multi-scale convolution of the CAM module, and effectively enhances the ability to extract small target features; equipped with a lightweight convolution module DBSS, it replaces the original standard convolution with deep separable convolution and SimAM attention mechanism, and greatly reduces the calculation volume; adopts the optimization strategy of combining DIoU loss and NWD loss function to accurately locate small targets. In the image defogging link, the CGANFormer algorithm innovates the traditional CycleGAN architecture, embeds the Transformer module into the generator network, uses the self-attention mechanism to capture global dependencies, and breaks through the convolutional local sensing field restrictions; the discriminator introduces a local-pheral combination architecture to jointly ensure the details and overall quality of the defogging image.

Experimental verification shows that compared with YOLOv11s, the EX-YOLO algorithm increased mAP0.5 to 0.893 on the TT100K data set, and the calculation volume was reduced to 17.0 GFLOPs; the mAP0.5 reached 0.390 on the VisDrone data set, and the calculation volume was only 15.4 GFLOPs, which was significantly optimized compared with the benchmark model. The CGANFormer algorithm has a PSNR of 21.0121 and SSIM of 0.9426 in the NYU2 data set. In the Dense-Haze data set, PSNR is 16.8625 and SSIM is 0.5879. The defogging effect comprehensively surpasses the comparison algorithm. After the integration of the two, the system has mAP0.5 up to 0.592 on the FOG-TT100K data set, and the accuracy and recall rate are increased to 0.699 and 0.449 respectively; mAP0.5 is 0.397 on the FOG-VisDrone data set, and the accuracy and recall rate are 0.721 and 0.074 respectively, and the comprehensive performance indicators are significantly superior.

The results of this research have opened up a new path for the detection of small targets in foggy traffic, which not only effectively improves the perception ability of intelligent traffic systems under complex meteorological conditions, but also lays a solid foundation for the wide application of drones in low-visibility environments, and promotes the deepening implementation of computer vision technology in the field of actual traffic management and unmanned vehicles, which is of great practical significance and application prospects.
\\
\\
\textbf{KEW WORDS:} Deep learning;  Target detection on foggy days;  Improve the YOLO algorithm;  CycleGAN Net;  Transformer Block
\end{enabstract}
\pagebreak